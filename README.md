# **Decoding Individual Words in Continuous Imagined Speech Using DeepSpeech on non-invasive EEG**

Carlos Valle, Carolina Mendez-Orellana, Christian Herff, and Maria Rodriguez-Fernandez.


Abstract: Speech Brain-Computer Interfaces (BCIs) have the potential to enable individuals to communicate without the need to move any muscles, while maintaining the naturalness of human speech. Although significant progress has been achieved in invasive speech BCIs, their application has been primarily limited to discrete decoding of individual words or sentences. Here, we show how an Automatic Speech Recognition (ASR) neural network can be applied to non-invasive EEG to decode individual words from speech perception and silent speech. By exploring the influence of word characteristics, we reveal that the network leverages temporal cues as well as the word identity, but not word length for decoding. In combination, this study opens a new avenue for the development of non-invasive speech neuroprosthesis by harnessing a successful model from ASR.



# Downloading the dataset
Instructions to download the dataset can be fount at repository [cgvalle/Large_Spanish_EEG](https://github.com/cgvalle/Large_Spanish_EEG)